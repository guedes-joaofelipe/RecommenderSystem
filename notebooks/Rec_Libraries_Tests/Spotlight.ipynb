{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.cross_validation import random_train_test_split\n",
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "from spotlight.evaluation import rmse_score\n",
    "from spotlight.factorization.explicit import ExplicitFactorizationModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_movielens_dataset(variant='100K')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([196, 186,  22, ..., 276,  13,  12])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.user_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = random_train_test_split(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = ExplicitFactorizationModel(n_iter=1)\n",
    "model.fit(train)\n",
    "\n",
    "rmse = rmse_score(model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99812853"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "\n",
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "from spotlight.cross_validation import user_based_train_test_split\n",
    "from spotlight.sequence.implicit import ImplicitSequenceModel\n",
    "from spotlight.sequence.representations import CNNNet\n",
    "from spotlight.evaluation import sequence_mrr_score\n",
    "\n",
    "\n",
    "CUDA = (os.environ.get('CUDA') is not None or\n",
    "        shutil.which('nvidia-smi') is not None)\n",
    "\n",
    "NUM_SAMPLES = 100\n",
    "\n",
    "LEARNING_RATES = [1e-3, 1e-2, 5 * 1e-2, 1e-1]\n",
    "LOSSES = ['bpr', 'hinge', 'adaptive_hinge', 'pointwise']\n",
    "BATCH_SIZE = [8, 16, 32, 256]\n",
    "EMBEDDING_DIM = [8, 16, 32, 64, 128, 256]\n",
    "N_ITER = list(range(5, 20))\n",
    "L2 = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 0.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Results:\n",
    "\n",
    "    def __init__(self, filename):\n",
    "\n",
    "        self._filename = filename\n",
    "\n",
    "        open(self._filename, 'a+')\n",
    "\n",
    "    def _hash(self, x):\n",
    "\n",
    "        return hashlib.md5(json.dumps(x, sort_keys=True).encode('utf-8')).hexdigest()\n",
    "\n",
    "    def save(self, hyperparams, test_mrr, validation_mrr):\n",
    "\n",
    "        result = {'test_mrr': test_mrr,\n",
    "                  'validation_mrr': validation_mrr,\n",
    "                  'hash': self._hash(hyperparams)}\n",
    "        result.update(hyperparams)\n",
    "\n",
    "        with open(self._filename, 'a+') as out:\n",
    "            out.write(json.dumps(result) + '\\n')\n",
    "\n",
    "    def best(self):\n",
    "\n",
    "        results = sorted([x for x in self],\n",
    "                         key=lambda x: -x['test_mrr'])\n",
    "\n",
    "        if results:\n",
    "            return results[0]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def __getitem__(self, hyperparams):\n",
    "\n",
    "        params_hash = self._hash(hyperparams)\n",
    "\n",
    "        with open(self._filename, 'r+') as fle:\n",
    "            for line in fle:\n",
    "                datum = json.loads(line)\n",
    "\n",
    "                if datum['hash'] == params_hash:\n",
    "                    del datum['hash']\n",
    "                    return datum\n",
    "\n",
    "        raise KeyError\n",
    "\n",
    "    def __contains__(self, x):\n",
    "\n",
    "        try:\n",
    "            self[x]\n",
    "            return True\n",
    "        except KeyError:\n",
    "            return False\n",
    "\n",
    "    def __iter__(self):\n",
    "\n",
    "        with open(self._filename, 'r+') as fle:\n",
    "            for line in fle:\n",
    "                datum = json.loads(line)\n",
    "\n",
    "                del datum['hash']\n",
    "\n",
    "                yield datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_cnn_hyperparameters(random_state, num):\n",
    "\n",
    "    space = {\n",
    "        'n_iter': N_ITER,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'l2': L2,\n",
    "        'learning_rate': LEARNING_RATES,\n",
    "        'loss': LOSSES,\n",
    "        'embedding_dim': EMBEDDING_DIM,\n",
    "        'kernel_width': [3, 5, 7],\n",
    "        'num_layers': list(range(1, 10)),\n",
    "        'dilation_multiplier': [1, 2],\n",
    "        'nonlinearity': ['tanh', 'relu'],\n",
    "        'residual': [True, False]\n",
    "    }\n",
    "\n",
    "    sampler = ParameterSampler(space,\n",
    "                               n_iter=num,\n",
    "                               random_state=random_state)\n",
    "\n",
    "    for params in sampler:\n",
    "        params['dilation'] = list(params['dilation_multiplier'] ** (i % 8)\n",
    "                                  for i in range(params['num_layers']))\n",
    "\n",
    "        yield params\n",
    "\n",
    "\n",
    "def sample_lstm_hyperparameters(random_state, num):\n",
    "\n",
    "    space = {\n",
    "        'n_iter': N_ITER,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'l2': L2,\n",
    "        'learning_rate': LEARNING_RATES,\n",
    "        'loss': LOSSES,\n",
    "        'embedding_dim': EMBEDDING_DIM,\n",
    "    }\n",
    "\n",
    "    sampler = ParameterSampler(space,\n",
    "                               n_iter=num,\n",
    "                               random_state=random_state)\n",
    "\n",
    "    for params in sampler:\n",
    "\n",
    "        yield params\n",
    "\n",
    "\n",
    "def sample_pooling_hyperparameters(random_state, num):\n",
    "\n",
    "    space = {\n",
    "        'n_iter': N_ITER,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'l2': L2,\n",
    "        'learning_rate': LEARNING_RATES,\n",
    "        'loss': LOSSES,\n",
    "        'embedding_dim': EMBEDDING_DIM,\n",
    "    }\n",
    "\n",
    "    sampler = ParameterSampler(space,\n",
    "                               n_iter=num,\n",
    "                               random_state=random_state)\n",
    "\n",
    "    for params in sampler:\n",
    "\n",
    "        yield params\n",
    "\n",
    "\n",
    "def evaluate_cnn_model(hyperparameters, train, test, validation, random_state):\n",
    "\n",
    "    h = hyperparameters\n",
    "\n",
    "    net = CNNNet(train.num_items,\n",
    "                 embedding_dim=h['embedding_dim'],\n",
    "                 kernel_width=h['kernel_width'],\n",
    "                 dilation=h['dilation'],\n",
    "                 num_layers=h['num_layers'],\n",
    "                 nonlinearity=h['nonlinearity'],\n",
    "                 residual_connections=h['residual'])\n",
    "\n",
    "    model = ImplicitSequenceModel(loss=h['loss'],\n",
    "                                  representation=net,\n",
    "                                  batch_size=h['batch_size'],\n",
    "                                  learning_rate=h['learning_rate'],\n",
    "                                  l2=h['l2'],\n",
    "                                  n_iter=h['n_iter'],\n",
    "                                  use_cuda=CUDA,\n",
    "                                  random_state=random_state)\n",
    "\n",
    "    model.fit(train, verbose=True)\n",
    "\n",
    "    test_mrr = sequence_mrr_score(model, test)\n",
    "    val_mrr = sequence_mrr_score(model, validation)\n",
    "\n",
    "    return test_mrr, val_mrr\n",
    "\n",
    "\n",
    "def evaluate_lstm_model(hyperparameters, train, test, validation, random_state):\n",
    "\n",
    "    h = hyperparameters\n",
    "\n",
    "    model = ImplicitSequenceModel(loss=h['loss'],\n",
    "                                  representation='lstm',\n",
    "                                  batch_size=h['batch_size'],\n",
    "                                  learning_rate=h['learning_rate'],\n",
    "                                  l2=h['l2'],\n",
    "                                  n_iter=h['n_iter'],\n",
    "                                  use_cuda=CUDA,\n",
    "                                  random_state=random_state)\n",
    "\n",
    "    model.fit(train, verbose=True)\n",
    "\n",
    "    test_mrr = sequence_mrr_score(model, test)\n",
    "    val_mrr = sequence_mrr_score(model, validation)\n",
    "\n",
    "    return test_mrr, val_mrr\n",
    "\n",
    "\n",
    "def evaluate_pooling_model(hyperparameters, train, test, validation, random_state):\n",
    "\n",
    "    h = hyperparameters\n",
    "\n",
    "    model = ImplicitSequenceModel(loss=h['loss'],\n",
    "                                  representation='pooling',\n",
    "                                  batch_size=h['batch_size'],\n",
    "                                  learning_rate=h['learning_rate'],\n",
    "                                  l2=h['l2'],\n",
    "                                  n_iter=h['n_iter'],\n",
    "                                  use_cuda=CUDA,\n",
    "                                  random_state=random_state)\n",
    "\n",
    "    model.fit(train, verbose=True)\n",
    "\n",
    "    test_mrr = sequence_mrr_score(model, test)\n",
    "    val_mrr = sequence_mrr_score(model, validation)\n",
    "\n",
    "    return test_mrr, val_mrr\n",
    "\n",
    "\n",
    "def run(train, test, validation, ranomd_state, model_type):\n",
    "\n",
    "    results = Results('{}_results.txt'.format(model_type))\n",
    "\n",
    "    best_result = results.best()\n",
    "\n",
    "    if model_type == 'pooling':\n",
    "        eval_fnc, sample_fnc = (evaluate_pooling_model,\n",
    "                                sample_pooling_hyperparameters)\n",
    "    elif model_type == 'cnn':\n",
    "        eval_fnc, sample_fnc = (evaluate_cnn_model,\n",
    "                                sample_cnn_hyperparameters)\n",
    "    elif model_type == 'lstm':\n",
    "        eval_fnc, sample_fnc = (evaluate_lstm_model,\n",
    "                                sample_lstm_hyperparameters)\n",
    "    else:\n",
    "        raise ValueError('Unknown model type')\n",
    "\n",
    "    if best_result is not None:\n",
    "        print('Best {} result: {}'.format(model_type, results.best()))\n",
    "\n",
    "    for hyperparameters in sample_fnc(random_state, NUM_SAMPLES):\n",
    "\n",
    "        if hyperparameters in results:\n",
    "            continue\n",
    "\n",
    "        print('Evaluating {}'.format(hyperparameters))\n",
    "\n",
    "        (test_mrr, val_mrr) = eval_fnc(hyperparameters,\n",
    "                                       train,\n",
    "                                       test,\n",
    "                                       validation,\n",
    "                                       random_state)\n",
    "\n",
    "        print('Test MRR {} val MRR {}'.format(\n",
    "            test_mrr.mean(), val_mrr.mean()\n",
    "        ))\n",
    "\n",
    "        results.save(hyperparameters, test_mrr.mean(), val_mrr.mean())\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best lstm result: {'test_mrr': 0.0715072408652459, 'validation_mrr': 0.05206514720948057, 'n_iter': 12, 'loss': 'adaptive_hinge', 'learning_rate': 0.01, 'l2': 1e-05, 'embedding_dim': 64, 'batch_size': 16}\n",
      "Evaluating {'n_iter': 18, 'loss': 'pointwise', 'learning_rate': 0.001, 'l2': 0.0001, 'embedding_dim': 256, 'batch_size': 8}\n",
      "Epoch 0: loss 0.6142163597729486\n",
      "Epoch 1: loss 0.552783812942176\n",
      "Epoch 2: loss 0.551816368677103\n",
      "Epoch 3: loss 0.5515939673756589\n",
      "Epoch 4: loss 0.5521511719357245\n",
      "Epoch 5: loss 0.5516734745854005\n",
      "Epoch 6: loss 0.551259459128136\n",
      "Epoch 7: loss 0.5518404812010517\n",
      "Epoch 8: loss 0.5519136595102326\n",
      "Epoch 9: loss 0.5522027738950482\n",
      "Epoch 10: loss 0.5515443409098739\n",
      "Epoch 11: loss 0.5518199085622282\n",
      "Epoch 12: loss 0.5521966641354646\n",
      "Epoch 13: loss 0.5512187051078511\n",
      "Epoch 14: loss 0.5515176999016126\n",
      "Epoch 15: loss 0.5513868021128719\n",
      "Epoch 16: loss 0.5509061320783408\n",
      "Epoch 17: loss 0.5524580020116427\n",
      "Test MRR 0.01158583186582557 val MRR 0.00935325051625385\n",
      "Evaluating {'n_iter': 8, 'loss': 'adaptive_hinge', 'learning_rate': 0.01, 'l2': 0.01, 'embedding_dim': 128, 'batch_size': 16}\n",
      "Epoch 0: loss 0.9986614007281578\n",
      "Epoch 1: loss 0.9980521711770826\n",
      "Epoch 2: loss 0.9981256482720092\n",
      "Epoch 3: loss 0.998114533633914\n",
      "Epoch 4: loss 0.9981490106027653\n",
      "Epoch 5: loss 0.9982366786999827\n",
      "Epoch 6: loss 0.9981205915045568\n",
      "Epoch 7: loss 0.9981579912246831\n",
      "Test MRR 0.01213023015631575 val MRR 0.009008033717078787\n",
      "Evaluating {'n_iter': 10, 'loss': 'pointwise', 'learning_rate': 0.1, 'l2': 1e-05, 'embedding_dim': 128, 'batch_size': 8}\n",
      "Epoch 0: loss 0.5709148473178306\n",
      "Epoch 1: loss 0.5669812677377186\n",
      "Epoch 2: loss 0.5653436121560731\n",
      "Epoch 3: loss 0.5667449576463484\n",
      "Epoch 4: loss 0.563661261064119\n",
      "Epoch 5: loss 0.5659891082401366\n",
      "Epoch 6: loss 0.5653171750864149\n",
      "Epoch 7: loss 0.5657840152841402\n",
      "Epoch 8: loss 0.5676170110560768\n",
      "Epoch 9: loss 0.566433387229332\n",
      "Test MRR 0.003133596541572716 val MRR 0.0035556152119109053\n",
      "Evaluating {'n_iter': 13, 'loss': 'adaptive_hinge', 'learning_rate': 0.01, 'l2': 1e-06, 'embedding_dim': 16, 'batch_size': 32}\n",
      "Epoch 0: loss 0.7523689282731423\n",
      "Epoch 1: loss 0.5001646431418957\n",
      "Epoch 2: loss 0.44880167087672446\n",
      "Epoch 3: loss 0.4254230194464679\n",
      "Epoch 4: loss 0.41072894470386595\n",
      "Epoch 5: loss 0.40221996428842227\n",
      "Epoch 6: loss 0.3952646429222342\n",
      "Epoch 7: loss 0.3905357335698548\n",
      "Epoch 8: loss 0.3862060545745054\n",
      "Epoch 9: loss 0.38292111618823915\n",
      "Epoch 10: loss 0.38083736662051126\n",
      "Epoch 11: loss 0.37740048582519964\n",
      "Epoch 12: loss 0.37608412021144305\n",
      "Test MRR 0.07469397876308849 val MRR 0.071496066175297\n",
      "Evaluating {'n_iter': 17, 'loss': 'hinge', 'learning_rate': 0.001, 'l2': 1e-06, 'embedding_dim': 128, 'batch_size': 8}\n",
      "Epoch 0: loss 0.4691421078799312\n",
      "Epoch 1: loss 0.4252780963280255\n",
      "Epoch 2: loss 0.34757135907690817\n",
      "Epoch 3: loss 0.29794796716585736\n",
      "Epoch 4: loss 0.27532380674029927\n",
      "Epoch 5: loss 0.24996953056272514\n",
      "Epoch 6: loss 0.22986278169999932\n",
      "Epoch 7: loss 0.2145642018417399\n",
      "Epoch 8: loss 0.2037392209918547\n",
      "Epoch 9: loss 0.1914846896327917\n",
      "Epoch 10: loss 0.18350173031532524\n",
      "Epoch 11: loss 0.17682437954844815\n",
      "Epoch 12: loss 0.17051008670600784\n",
      "Epoch 13: loss 0.16628352863610005\n",
      "Epoch 14: loss 0.16136255915255665\n",
      "Epoch 15: loss 0.15769894115458488\n",
      "Epoch 16: loss 0.15489891223724617\n",
      "Test MRR 0.05417273058698474 val MRR 0.05821316171176594\n",
      "Evaluating {'n_iter': 19, 'loss': 'adaptive_hinge', 'learning_rate': 0.001, 'l2': 0.01, 'embedding_dim': 8, 'batch_size': 32}\n",
      "Epoch 0: loss 0.9978952424786102\n",
      "Epoch 1: loss 0.9956592343994791\n",
      "Epoch 2: loss 0.9953941465554079\n",
      "Epoch 3: loss 0.995266260976475\n",
      "Epoch 4: loss 0.995249956140021\n",
      "Epoch 5: loss 0.9953071729266812\n",
      "Epoch 6: loss 0.9954151756955549\n",
      "Epoch 7: loss 0.9953693224920481\n",
      "Epoch 8: loss 0.995320209394699\n",
      "Epoch 9: loss 0.9952348736225146\n",
      "Epoch 10: loss 0.9952140382680847\n",
      "Epoch 11: loss 0.9953326879519422\n",
      "Epoch 12: loss 0.9953665792659561\n",
      "Epoch 13: loss 0.9952905929484074\n",
      "Epoch 14: loss 0.9952918107475714\n",
      "Epoch 15: loss 0.9953988163392126\n",
      "Epoch 16: loss 0.9953587620179235\n",
      "Epoch 17: loss 0.9953368210114574\n",
      "Epoch 18: loss 0.9951773715245216\n",
      "Test MRR 0.013268065848134274 val MRR 0.009514716530291697\n",
      "Evaluating {'n_iter': 16, 'loss': 'pointwise', 'learning_rate': 0.01, 'l2': 1e-05, 'embedding_dim': 64, 'batch_size': 256}\n",
      "Epoch 0: loss 0.6698310993335865\n",
      "Epoch 1: loss 0.5217947496308221\n",
      "Epoch 2: loss 0.5244247714678446\n",
      "Epoch 3: loss 0.5258561968803406\n",
      "Epoch 4: loss 0.5245769001819469\n",
      "Epoch 5: loss 0.5239228562072471\n",
      "Epoch 6: loss 0.5251005976288406\n",
      "Epoch 7: loss 0.5243540030938608\n",
      "Epoch 8: loss 0.5238637328147888\n",
      "Epoch 9: loss 0.5252160606560884\n",
      "Epoch 10: loss 0.5242027905252244\n",
      "Epoch 11: loss 0.5243738801391037\n",
      "Epoch 12: loss 0.5239415014231646\n",
      "Epoch 13: loss 0.5230843424797058\n",
      "Epoch 14: loss 0.524902758774934\n",
      "Epoch 15: loss 0.524458008783835\n",
      "Test MRR 0.013364635942820573 val MRR 0.00940772290174842\n",
      "Evaluating {'n_iter': 14, 'loss': 'adaptive_hinge', 'learning_rate': 0.05, 'l2': 0.01, 'embedding_dim': 8, 'batch_size': 256}\n",
      "Epoch 0: loss 1.0021538822739213\n",
      "Epoch 1: loss 0.9975197822959335\n",
      "Epoch 2: loss 0.9973867071999444\n",
      "Epoch 3: loss 0.9971739804303205\n",
      "Epoch 4: loss 0.9973850073637786\n",
      "Epoch 5: loss 0.9974856862315425\n",
      "Epoch 6: loss 0.997560461362203\n",
      "Epoch 7: loss 0.9979632850046511\n",
      "Epoch 8: loss 0.9982275234328376\n",
      "Epoch 9: loss 0.9982404090740062\n",
      "Epoch 10: loss 0.9983485120314138\n",
      "Epoch 11: loss 0.9977460812639307\n",
      "Epoch 12: loss 0.9979100933781376\n",
      "Epoch 13: loss 0.9977843915974652\n",
      "Test MRR 0.013902967460982275 val MRR 0.008903565395379938\n",
      "Evaluating {'n_iter': 7, 'loss': 'hinge', 'learning_rate': 0.001, 'l2': 0.0, 'embedding_dim': 32, 'batch_size': 32}\n",
      "Epoch 0: loss 0.5251498052859194\n",
      "Epoch 1: loss 0.43576063342851484\n",
      "Epoch 2: loss 0.43156739165432645\n",
      "Epoch 3: loss 0.42204460106189784\n",
      "Epoch 4: loss 0.4036974228953863\n",
      "Epoch 5: loss 0.36317809950118946\n",
      "Epoch 6: loss 0.3239465351635811\n",
      "Test MRR 0.017739528719351933 val MRR 0.012210918467598118\n",
      "Evaluating {'n_iter': 6, 'loss': 'bpr', 'learning_rate': 0.1, 'l2': 0.01, 'embedding_dim': 128, 'batch_size': 8}\n",
      "Epoch 0: loss 0.4965193678096699\n",
      "Epoch 1: loss 0.49653231240055934\n",
      "Epoch 2: loss 0.49654141291710197\n",
      "Epoch 3: loss 0.49652117129313394\n",
      "Epoch 4: loss 0.4965061071228046\n",
      "Epoch 5: loss 0.49652240016939525\n",
      "Test MRR 0.005565780719937032 val MRR 0.0048355126246938775\n",
      "Evaluating {'n_iter': 18, 'loss': 'adaptive_hinge', 'learning_rate': 0.001, 'l2': 0.001, 'embedding_dim': 16, 'batch_size': 16}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "\n",
    "max_sequence_length = 200\n",
    "min_sequence_length = 20\n",
    "step_size = 200\n",
    "random_state = np.random.RandomState(100)\n",
    "\n",
    "dataset = get_movielens_dataset('1M')\n",
    "\n",
    "train, rest = user_based_train_test_split(dataset,\n",
    "                                          random_state=random_state)\n",
    "test, validation = user_based_train_test_split(rest,\n",
    "                                               test_percentage=0.5,\n",
    "                                               random_state=random_state)\n",
    "train = train.to_sequence(max_sequence_length=max_sequence_length,\n",
    "                          min_sequence_length=min_sequence_length,\n",
    "                          step_size=step_size)\n",
    "test = test.to_sequence(max_sequence_length=max_sequence_length,\n",
    "                        min_sequence_length=min_sequence_length,\n",
    "                        step_size=step_size)\n",
    "validation = validation.to_sequence(max_sequence_length=max_sequence_length,\n",
    "                                    min_sequence_length=min_sequence_length,\n",
    "                                    step_size=step_size)\n",
    "\n",
    "mode = sys.argv[1]\n",
    "\n",
    "run(train, test, validation, random_state, \"lstm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "https://github.com/maciejkula/spotlight/tree/master/examples/movielens_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from spotlight.sequence.implicit import ImplicitSequenceModel\n",
    "from spotlight.sequence.representations import CNNNet\n",
    "from spotlight.evaluation import sequence_mrr_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hyperparameters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-35186bb2426f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m net = CNNNet(train.num_items,\n\u001b[1;32m----> 3\u001b[1;33m              \u001b[0membedding_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'embedding_dim'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m              \u001b[0mkernel_width\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'kernel_width'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m              \u001b[0mdilation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dilation'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hyperparameters' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "net = CNNNet(train.num_items,\n",
    "             embedding_dim=hyperparameters['embedding_dim'],\n",
    "             kernel_width=hyperparameters['kernel_width'],\n",
    "             dilation=hyperparameters['dilation'],\n",
    "             num_layers=hyperparameters['num_layers'],\n",
    "             nonlinearity=hyperparameters['nonlinearity'],\n",
    "             residual_connections=hyperparameters['residual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "model = ImplicitSequenceModel(loss=hyperparameters['loss'],\n",
    "                              representation=net,\n",
    "                              batch_size=hyperparameters['batch_size'],\n",
    "                              learning_rate=hyperparameters['learning_rate'],\n",
    "                              l2=hyperparameters['l2'],\n",
    "                              n_iter=hyperparameters['n_iter'],\n",
    "                              use_cuda=torch.cuda.is_available(),\n",
    "                              random_state=random_state)\n",
    "\n",
    "model.fit(train)\n",
    "\n",
    "test_mrr = sequence_mrr_score(model, test)\n",
    "val_mrr = sequence_mrr_score(model, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "\n",
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "from spotlight.cross_validation import user_based_train_test_split\n",
    "from spotlight.sequence.implicit import ImplicitSequenceModel\n",
    "from spotlight.sequence.representations import CNNNet\n",
    "from spotlight.evaluation import sequence_mrr_score\n",
    "\n",
    "\n",
    "CUDA = (os.environ.get('CUDA') is not None or\n",
    "        shutil.which('nvidia-smi') is not None)\n",
    "\n",
    "NUM_SAMPLES = 100\n",
    "\n",
    "LEARNING_RATES = [1e-3, 1e-2, 5 * 1e-2, 1e-1]\n",
    "LOSSES = ['bpr', 'hinge', 'adaptive_hinge', 'pointwise']\n",
    "BATCH_SIZE = [8, 16, 32, 256]\n",
    "EMBEDDING_DIM = [8, 16, 32, 64, 128, 256]\n",
    "N_ITER = list(range(5, 20))\n",
    "L2 = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 0.0]\n",
    "\n",
    "\n",
    "class Results:\n",
    "\n",
    "    def __init__(self, filename):\n",
    "\n",
    "        self._filename = filename\n",
    "\n",
    "        open(self._filename, 'a+')\n",
    "\n",
    "    def _hash(self, x):\n",
    "\n",
    "        return hashlib.md5(json.dumps(x, sort_keys=True).encode('utf-8')).hexdigest()\n",
    "\n",
    "    def save(self, hyperparams, test_mrr, validation_mrr):\n",
    "\n",
    "        result = {'test_mrr': test_mrr,\n",
    "                  'validation_mrr': validation_mrr,\n",
    "                  'hash': self._hash(hyperparams)}\n",
    "        result.update(hyperparams)\n",
    "\n",
    "        with open(self._filename, 'a+') as out:\n",
    "            out.write(json.dumps(result) + '\\n')\n",
    "\n",
    "    def best(self):\n",
    "\n",
    "        results = sorted([x for x in self],\n",
    "                         key=lambda x: -x['test_mrr'])\n",
    "\n",
    "        if results:\n",
    "            return results[0]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def __getitem__(self, hyperparams):\n",
    "\n",
    "        params_hash = self._hash(hyperparams)\n",
    "\n",
    "        with open(self._filename, 'r+') as fle:\n",
    "            for line in fle:\n",
    "                datum = json.loads(line)\n",
    "\n",
    "                if datum['hash'] == params_hash:\n",
    "                    del datum['hash']\n",
    "                    return datum\n",
    "\n",
    "        raise KeyError\n",
    "\n",
    "    def __contains__(self, x):\n",
    "\n",
    "        try:\n",
    "            self[x]\n",
    "            return True\n",
    "        except KeyError:\n",
    "            return False\n",
    "\n",
    "    def __iter__(self):\n",
    "\n",
    "        with open(self._filename, 'r+') as fle:\n",
    "            for line in fle:\n",
    "                datum = json.loads(line)\n",
    "\n",
    "                del datum['hash']\n",
    "\n",
    "                yield datum\n",
    "\n",
    "\n",
    "def sample_cnn_hyperparameters(random_state, num):\n",
    "\n",
    "    space = {\n",
    "        'n_iter': N_ITER,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'l2': L2,\n",
    "        'learning_rate': LEARNING_RATES,\n",
    "        'loss': LOSSES,\n",
    "        'embedding_dim': EMBEDDING_DIM,\n",
    "        'kernel_width': [3, 5, 7],\n",
    "        'num_layers': list(range(1, 10)),\n",
    "        'dilation_multiplier': [1, 2],\n",
    "        'nonlinearity': ['tanh', 'relu'],\n",
    "        'residual': [True, False]\n",
    "    }\n",
    "\n",
    "    sampler = ParameterSampler(space,\n",
    "                               n_iter=num,\n",
    "                               random_state=random_state)\n",
    "\n",
    "    for params in sampler:\n",
    "        params['dilation'] = list(params['dilation_multiplier'] ** (i % 8)\n",
    "                                  for i in range(params['num_layers']))\n",
    "\n",
    "        yield params\n",
    "\n",
    "\n",
    "def sample_lstm_hyperparameters(random_state, num):\n",
    "\n",
    "    space = {\n",
    "        'n_iter': N_ITER,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'l2': L2,\n",
    "        'learning_rate': LEARNING_RATES,\n",
    "        'loss': LOSSES,\n",
    "        'embedding_dim': EMBEDDING_DIM,\n",
    "    }\n",
    "\n",
    "    sampler = ParameterSampler(space,\n",
    "                               n_iter=num,\n",
    "                               random_state=random_state)\n",
    "\n",
    "    for params in sampler:\n",
    "\n",
    "        yield params\n",
    "\n",
    "\n",
    "def sample_pooling_hyperparameters(random_state, num):\n",
    "\n",
    "    space = {\n",
    "        'n_iter': N_ITER,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'l2': L2,\n",
    "        'learning_rate': LEARNING_RATES,\n",
    "        'loss': LOSSES,\n",
    "        'embedding_dim': EMBEDDING_DIM,\n",
    "    }\n",
    "\n",
    "    sampler = ParameterSampler(space,\n",
    "                               n_iter=num,\n",
    "                               random_state=random_state)\n",
    "\n",
    "    for params in sampler:\n",
    "\n",
    "        yield params\n",
    "\n",
    "\n",
    "def evaluate_cnn_model(hyperparameters, train, test, validation, random_state):\n",
    "\n",
    "    h = hyperparameters\n",
    "\n",
    "    net = CNNNet(train.num_items,\n",
    "                 embedding_dim=h['embedding_dim'],\n",
    "                 kernel_width=h['kernel_width'],\n",
    "                 dilation=h['dilation'],\n",
    "                 num_layers=h['num_layers'],\n",
    "                 nonlinearity=h['nonlinearity'],\n",
    "                 residual_connections=h['residual'])\n",
    "\n",
    "    model = ImplicitSequenceModel(loss=h['loss'],\n",
    "                                  representation=net,\n",
    "                                  batch_size=h['batch_size'],\n",
    "                                  learning_rate=h['learning_rate'],\n",
    "                                  l2=h['l2'],\n",
    "                                  n_iter=h['n_iter'],\n",
    "                                  use_cuda=CUDA,\n",
    "                                  random_state=random_state)\n",
    "\n",
    "    model.fit(train, verbose=True)\n",
    "\n",
    "    test_mrr = sequence_mrr_score(model, test)\n",
    "    val_mrr = sequence_mrr_score(model, validation)\n",
    "\n",
    "    return test_mrr, val_mrr\n",
    "\n",
    "\n",
    "def evaluate_lstm_model(hyperparameters, train, test, validation, random_state):\n",
    "\n",
    "    h = hyperparameters\n",
    "\n",
    "    model = ImplicitSequenceModel(loss=h['loss'],\n",
    "                                  representation='lstm',\n",
    "                                  batch_size=h['batch_size'],\n",
    "                                  learning_rate=h['learning_rate'],\n",
    "                                  l2=h['l2'],\n",
    "                                  n_iter=h['n_iter'],\n",
    "                                  use_cuda=CUDA,\n",
    "                                  random_state=random_state)\n",
    "\n",
    "    model.fit(train, verbose=True)\n",
    "\n",
    "    test_mrr = sequence_mrr_score(model, test)\n",
    "    val_mrr = sequence_mrr_score(model, validation)\n",
    "\n",
    "    return test_mrr, val_mrr\n",
    "\n",
    "\n",
    "def evaluate_pooling_model(hyperparameters, train, test, validation, random_state):\n",
    "\n",
    "    h = hyperparameters\n",
    "\n",
    "    model = ImplicitSequenceModel(loss=h['loss'],\n",
    "                                  representation='pooling',\n",
    "                                  batch_size=h['batch_size'],\n",
    "                                  learning_rate=h['learning_rate'],\n",
    "                                  l2=h['l2'],\n",
    "                                  n_iter=h['n_iter'],\n",
    "                                  use_cuda=CUDA,\n",
    "                                  random_state=random_state)\n",
    "\n",
    "    model.fit(train, verbose=True)\n",
    "\n",
    "    test_mrr = sequence_mrr_score(model, test)\n",
    "    val_mrr = sequence_mrr_score(model, validation)\n",
    "\n",
    "    return test_mrr, val_mrr\n",
    "\n",
    "\n",
    "def run(train, test, validation, ranomd_state, model_type):\n",
    "\n",
    "    results = Results('{}_results.txt'.format(model_type))\n",
    "\n",
    "    best_result = results.best()\n",
    "\n",
    "    if model_type == 'pooling':\n",
    "        eval_fnc, sample_fnc = (evaluate_pooling_model,\n",
    "                                sample_pooling_hyperparameters)\n",
    "    elif model_type == 'cnn':\n",
    "        eval_fnc, sample_fnc = (evaluate_cnn_model,\n",
    "                                sample_cnn_hyperparameters)\n",
    "    elif model_type == 'lstm':\n",
    "        eval_fnc, sample_fnc = (evaluate_lstm_model,\n",
    "                                sample_lstm_hyperparameters)\n",
    "    else:\n",
    "        raise ValueError('Unknown model type')\n",
    "\n",
    "    if best_result is not None:\n",
    "        print('Best {} result: {}'.format(model_type, results.best()))\n",
    "\n",
    "    for hyperparameters in sample_fnc(random_state, NUM_SAMPLES):\n",
    "\n",
    "        if hyperparameters in results:\n",
    "            continue\n",
    "\n",
    "        print('Evaluating {}'.format(hyperparameters))\n",
    "\n",
    "        (test_mrr, val_mrr) = eval_fnc(hyperparameters,\n",
    "                                       train,\n",
    "                                       test,\n",
    "                                       validation,\n",
    "                                       random_state)\n",
    "\n",
    "        print('Test MRR {} val MRR {}'.format(\n",
    "            test_mrr.mean(), val_mrr.mean()\n",
    "        ))\n",
    "\n",
    "        results.save(hyperparameters, test_mrr.mean(), val_mrr.mean())\n",
    "\n",
    "    return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating {'n_iter': 7, 'loss': 'pointwise', 'learning_rate': 0.1, 'l2': 0.01, 'embedding_dim': 64, 'batch_size': 16}\n",
      "Epoch 0: loss 0.9932104746500651\n",
      "Epoch 1: loss 0.9933011090313947\n",
      "Epoch 2: loss 0.9933347083904125\n",
      "Epoch 3: loss 0.9930821844825038\n",
      "Epoch 4: loss 0.9932906749071898\n",
      "Epoch 5: loss 0.9932020858482078\n",
      "Epoch 6: loss 0.9933682282765707\n",
      "Test MRR 0.009311773602424429 val MRR 0.017236301384196847\n",
      "Evaluating {'n_iter': 19, 'loss': 'pointwise', 'learning_rate': 0.01, 'l2': 0.0001, 'embedding_dim': 32, 'batch_size': 16}\n",
      "Epoch 0: loss 0.6292342024820822\n",
      "Epoch 1: loss 0.5382471680641174\n",
      "Epoch 2: loss 0.5367336477394458\n",
      "Epoch 3: loss 0.5368922573548777\n",
      "Epoch 4: loss 0.5352822602898987\n",
      "Epoch 5: loss 0.5366321244725475\n",
      "Epoch 6: loss 0.5387835447435025\n",
      "Epoch 7: loss 0.5363076787303995\n",
      "Epoch 8: loss 0.5367333657211728\n",
      "Epoch 9: loss 0.5411565706685737\n",
      "Epoch 10: loss 0.5366828838984171\n",
      "Epoch 11: loss 0.5410515196897365\n",
      "Epoch 12: loss 0.5400070537019659\n",
      "Epoch 13: loss 0.5402124772469202\n",
      "Epoch 14: loss 0.5440084730033521\n",
      "Epoch 15: loss 0.5405072967211405\n",
      "Epoch 16: loss 0.5374337710716106\n",
      "Epoch 17: loss 0.5381560458077325\n",
      "Epoch 18: loss 0.5403349233998193\n",
      "Test MRR 0.0091530509011098 val MRR 0.01219640452312115\n",
      "Evaluating {'n_iter': 9, 'loss': 'hinge', 'learning_rate': 0.01, 'l2': 1e-06, 'embedding_dim': 8, 'batch_size': 8}\n",
      "Epoch 0: loss 0.5020824113738871\n",
      "Epoch 1: loss 0.44136600628077427\n",
      "Epoch 2: loss 0.38949349439032727\n",
      "Epoch 3: loss 0.31872034699560325\n",
      "Epoch 4: loss 0.2761499483451665\n",
      "Epoch 5: loss 0.24095262712407334\n",
      "Epoch 6: loss 0.2207840901111888\n",
      "Epoch 7: loss 0.21313771508007406\n",
      "Epoch 8: loss 0.20563749481584423\n",
      "Test MRR 0.025522294423059845 val MRR 0.03710613714287982\n",
      "Evaluating {'n_iter': 19, 'loss': 'adaptive_hinge', 'learning_rate': 0.1, 'l2': 1e-05, 'embedding_dim': 256, 'batch_size': 16}\n",
      "Epoch 0: loss 0.978177218525498\n",
      "Epoch 1: loss 0.7747291194068061\n",
      "Epoch 2: loss 0.7261798403881214\n",
      "Epoch 3: loss 0.717058296556826\n",
      "Epoch 4: loss 0.7097399411378084\n",
      "Epoch 5: loss 0.7051771835044578\n",
      "Epoch 6: loss 0.6979590091440413\n",
      "Epoch 7: loss 0.6951269551559731\n",
      "Epoch 8: loss 0.6891916339044217\n",
      "Epoch 9: loss 0.688832680384318\n",
      "Epoch 10: loss 0.6926520764827728\n",
      "Epoch 11: loss 0.6867113521805516\n",
      "Epoch 12: loss 0.6909308599101173\n",
      "Epoch 13: loss 0.6887144810623593\n",
      "Epoch 14: loss 0.6780411821824534\n",
      "Epoch 15: loss 0.6752707075189661\n",
      "Epoch 16: loss 0.685594524498339\n",
      "Epoch 17: loss 0.6818557900411112\n",
      "Epoch 18: loss 0.6913160207094969\n",
      "Test MRR 0.024764523468685493 val MRR 0.024748206038919345\n",
      "Evaluating {'n_iter': 14, 'loss': 'pointwise', 'learning_rate': 0.05, 'l2': 0.001, 'embedding_dim': 256, 'batch_size': 16}\n",
      "Epoch 0: loss 0.6787613045286249\n",
      "Epoch 1: loss 0.656516468083417\n",
      "Epoch 2: loss 0.6572119317672871\n",
      "Epoch 3: loss 0.652315373773928\n",
      "Epoch 4: loss 0.6569009655051761\n",
      "Epoch 5: loss 0.6588193873564402\n",
      "Epoch 6: loss 0.6556139952606626\n",
      "Epoch 7: loss 0.6544349977263698\n",
      "Epoch 8: loss 0.6572220557265811\n",
      "Epoch 9: loss 0.6542991068628099\n",
      "Epoch 10: loss 0.6542087153152183\n",
      "Epoch 11: loss 0.6572921651381033\n",
      "Epoch 12: loss 0.6569352999881461\n",
      "Epoch 13: loss 0.6561709278159671\n",
      "Test MRR 0.007244088452016802 val MRR 0.0068413775004406\n",
      "Evaluating {'n_iter': 15, 'loss': 'adaptive_hinge', 'learning_rate': 0.01, 'l2': 0.0, 'embedding_dim': 64, 'batch_size': 16}\n",
      "Epoch 0: loss 0.9324998005672738\n",
      "Epoch 1: loss 0.7237418128384484\n",
      "Epoch 2: loss 0.6712202407695629\n",
      "Epoch 3: loss 0.6416778122937238\n",
      "Epoch 4: loss 0.6212808031726766\n",
      "Epoch 5: loss 0.5997754666540358\n",
      "Epoch 6: loss 0.5894058385380992\n",
      "Epoch 7: loss 0.5761813681434702\n",
      "Epoch 8: loss 0.5654797758217212\n",
      "Epoch 9: loss 0.5561085415107233\n",
      "Epoch 10: loss 0.5474250482188331\n",
      "Epoch 11: loss 0.5401186148325602\n",
      "Epoch 12: loss 0.5322404967414008\n",
      "Epoch 13: loss 0.5237854349392431\n",
      "Epoch 14: loss 0.5149063964684805\n",
      "Test MRR 0.0508456061492707 val MRR 0.03689665044931115\n",
      "Evaluating {'n_iter': 7, 'loss': 'bpr', 'learning_rate': 0.001, 'l2': 1e-06, 'embedding_dim': 16, 'batch_size': 16}\n",
      "Epoch 0: loss 0.440955337550905\n",
      "Epoch 1: loss 0.2593760054420542\n",
      "Epoch 2: loss 0.22953164246347216\n",
      "Epoch 3: loss 0.2193437960964662\n",
      "Epoch 4: loss 0.2137836601447176\n",
      "Epoch 5: loss 0.21024674287548772\n",
      "Epoch 6: loss 0.20855936214879708\n",
      "Test MRR 0.009630677455542674 val MRR 0.015925956554822755\n",
      "Evaluating {'n_iter': 18, 'loss': 'bpr', 'learning_rate': 0.05, 'l2': 1e-05, 'embedding_dim': 32, 'batch_size': 32}\n",
      "Epoch 0: loss 0.24108760721153683\n",
      "Epoch 1: loss 0.20496502684222329\n",
      "Epoch 2: loss 0.20584725229828446\n",
      "Epoch 3: loss 0.20532792641056907\n",
      "Epoch 4: loss 0.2041694196286025\n",
      "Epoch 5: loss 0.20456745116798966\n",
      "Epoch 6: loss 0.204285372738485\n",
      "Epoch 7: loss 0.20482464355451088\n",
      "Epoch 8: loss 0.1999439337739238\n",
      "Epoch 9: loss 0.20091747520146547\n",
      "Epoch 10: loss 0.18625788280257471\n",
      "Epoch 11: loss 0.16980311771233877\n",
      "Epoch 12: loss 0.1633800792473334\n",
      "Epoch 13: loss 0.15855873348536315\n",
      "Epoch 14: loss 0.14764181248567723\n",
      "Epoch 15: loss 0.13823272260250868\n",
      "Epoch 16: loss 0.1321472059245463\n",
      "Epoch 17: loss 0.12701566103431913\n",
      "Test MRR 0.03230311722655987 val MRR 0.01730258175430912\n",
      "Evaluating {'n_iter': 5, 'loss': 'adaptive_hinge', 'learning_rate': 0.1, 'l2': 0.001, 'embedding_dim': 64, 'batch_size': 16}\n",
      "Epoch 0: loss 0.9246913879005997\n",
      "Epoch 1: loss 0.8157513649375351\n",
      "Epoch 2: loss 1.0868914734434199\n",
      "Epoch 3: loss 0.9659462019249245\n",
      "Epoch 4: loss 0.8839453525013394\n",
      "Test MRR 0.03456431000429712 val MRR 0.02483253352754064\n",
      "Evaluating {'n_iter': 11, 'loss': 'bpr', 'learning_rate': 0.05, 'l2': 0.0, 'embedding_dim': 64, 'batch_size': 8}\n",
      "Epoch 0: loss 0.22948404798440844\n",
      "Epoch 1: loss 0.20145940223586895\n",
      "Epoch 2: loss 0.19139129285500428\n",
      "Epoch 3: loss 0.1622699166291228\n",
      "Epoch 4: loss 0.14820466622292439\n",
      "Epoch 5: loss 0.14492009858661722\n",
      "Epoch 6: loss 0.13940134282424071\n",
      "Epoch 7: loss 0.13848723150859368\n",
      "Epoch 8: loss 0.13673069756303993\n",
      "Epoch 9: loss 0.13552911224487785\n",
      "Epoch 10: loss 0.1354077159662113\n",
      "Test MRR 0.012357116769641243 val MRR 0.019526563652133535\n",
      "Evaluating {'n_iter': 12, 'loss': 'adaptive_hinge', 'learning_rate': 0.01, 'l2': 1e-05, 'embedding_dim': 64, 'batch_size': 16}\n",
      "Epoch 0: loss 0.9332242630146168\n",
      "Epoch 1: loss 0.7114538075747313\n",
      "Epoch 2: loss 0.6693451117586207\n",
      "Epoch 3: loss 0.6381680722589846\n",
      "Epoch 4: loss 0.6150528578846542\n",
      "Epoch 5: loss 0.6058563899110865\n",
      "Epoch 6: loss 0.5894425638295986\n",
      "Epoch 7: loss 0.5810249856224766\n",
      "Epoch 8: loss 0.5693554436718976\n",
      "Epoch 9: loss 0.552566808131006\n",
      "Epoch 10: loss 0.5472645516748782\n",
      "Epoch 11: loss 0.5419054666051158\n",
      "Test MRR 0.0715072408652459 val MRR 0.05206514720948057\n",
      "Evaluating {'n_iter': 5, 'loss': 'bpr', 'learning_rate': 0.05, 'l2': 0.0001, 'embedding_dim': 32, 'batch_size': 32}\n",
      "Epoch 0: loss 0.24824725091457367\n",
      "Epoch 1: loss 0.2249132632105439\n",
      "Epoch 2: loss 0.2247468498018053\n",
      "Epoch 3: loss 0.22812133254828276\n",
      "Epoch 4: loss 0.22871877363434545\n",
      "Test MRR 0.010567115959070079 val MRR 0.016098526815333965\n",
      "Evaluating {'n_iter': 10, 'loss': 'adaptive_hinge', 'learning_rate': 0.01, 'l2': 1e-05, 'embedding_dim': 8, 'batch_size': 256}\n",
      "Epoch 0: loss 1.0080745816230774\n",
      "Epoch 1: loss 1.0018375515937805\n",
      "Epoch 2: loss 0.9987762272357941\n",
      "Epoch 3: loss 0.9942096769809723\n",
      "Epoch 4: loss 0.9783450365066528\n",
      "Epoch 5: loss 0.9406051486730576\n",
      "Epoch 6: loss 0.9155552834272385\n",
      "Epoch 7: loss 0.8773812353610992\n",
      "Epoch 8: loss 0.8220594227313995\n",
      "Epoch 9: loss 0.795132040977478\n",
      "Test MRR 0.016506817681964648 val MRR 0.02542309626488943\n",
      "Evaluating {'n_iter': 14, 'loss': 'hinge', 'learning_rate': 0.1, 'l2': 1e-05, 'embedding_dim': 8, 'batch_size': 32}\n",
      "Epoch 0: loss 0.5177614843403852\n",
      "Epoch 1: loss 0.4217583790973381\n",
      "Epoch 2: loss 0.3476563912850839\n",
      "Epoch 3: loss 0.2909927158444016\n",
      "Epoch 4: loss 0.26918511313420757\n",
      "Epoch 5: loss 0.25632540660875813\n",
      "Epoch 6: loss 0.25137059832060776\n",
      "Epoch 7: loss 0.2517110236265041\n",
      "Epoch 8: loss 0.2450464947356118\n",
      "Epoch 9: loss 0.24516391974908333\n",
      "Epoch 10: loss 0.2431945381341157\n",
      "Epoch 11: loss 0.24151425781073393\n",
      "Epoch 12: loss 0.24006560389642362\n",
      "Epoch 13: loss 0.2419888355113842\n",
      "Test MRR 0.026334520352092855 val MRR 0.02628410693276642\n",
      "Evaluating {'n_iter': 18, 'loss': 'pointwise', 'learning_rate': 0.001, 'l2': 0.0001, 'embedding_dim': 256, 'batch_size': 8}\n",
      "Epoch 0: loss 0.8326070347678995\n",
      "Epoch 1: loss 0.6013422157162818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: loss 0.5636001869896862\n",
      "Epoch 3: loss 0.5487736246296179\n",
      "Epoch 4: loss 0.5415369545187906\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-55743681609b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'lstm'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-76d8df7171d9>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(train, test, validation, ranomd_state, model_type)\u001b[0m\n\u001b[0;32m    264\u001b[0m                                        \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m                                        \u001b[0mvalidation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m                                        random_state)\n\u001b[0m\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         print('Test MRR {} val MRR {}'.format(\n",
      "\u001b[1;32m<ipython-input-8-76d8df7171d9>\u001b[0m in \u001b[0;36mevaluate_lstm_model\u001b[1;34m(hyperparameters, train, test, validation, random_state)\u001b[0m\n\u001b[0;32m    203\u001b[0m                                   random_state=random_state)\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[0mtest_mrr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msequence_mrr_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\spotlight\\sequence\\implicit.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, interactions, verbose)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m                 user_representation, _ = self._net.user_representation(\n\u001b[1;32m--> 231\u001b[1;33m                     \u001b[0msequence_var\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m                 )\n\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\spotlight\\sequence\\representations.py\u001b[0m in \u001b[0;36muser_representation\u001b[1;34m(self, item_sequences)\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[0msequence_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msequence_embeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[0muser_representations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence_embeddings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m         \u001b[0muser_representations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muser_representations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         )\n\u001b[1;32m--> 192\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\torch\\nn\\_functions\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\torch\\nn\\_functions\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(input, weight, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[0mnexth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvariable_length\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\torch\\nn\\_functions\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m                 \u001b[0mhy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\torch\\nn\\_functions\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m             \u001b[1;31m# hack to handle LSTM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\torch\\nn\\_functions\\rnn.py\u001b[0m in \u001b[0;36mLSTMCell\u001b[1;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mforgetgate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforgetgate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mcellgate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcellgate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0moutgate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutgate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mcy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mforgetgate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mingate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcellgate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36msigmoid\u001b[1;34m(input)\u001b[0m\n\u001b[0;32m    972\u001b[0m     \u001b[0mSee\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;32mclass\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSigmoid\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mdetails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    973\u001b[0m     \"\"\"\n\u001b[1;32m--> 974\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    975\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    # if __name__ == '__main__':\n",
    "\n",
    "    max_sequence_length = 200\n",
    "    min_sequence_length = 20\n",
    "    step_size = 200\n",
    "    random_state = np.random.RandomState(100)\n",
    "\n",
    "    dataset = get_movielens_dataset('100K')\n",
    "\n",
    "    train, rest = user_based_train_test_split(dataset,\n",
    "                                              random_state=random_state)\n",
    "    test, validation = user_based_train_test_split(rest,\n",
    "                                                   test_percentage=0.5,\n",
    "                                                   random_state=random_state)\n",
    "    train = train.to_sequence(max_sequence_length=max_sequence_length,\n",
    "                              min_sequence_length=min_sequence_length,\n",
    "                              step_size=step_size)\n",
    "    test = test.to_sequence(max_sequence_length=max_sequence_length,\n",
    "                            min_sequence_length=min_sequence_length,\n",
    "                            step_size=step_size)\n",
    "    validation = validation.to_sequence(max_sequence_length=max_sequence_length,\n",
    "                                        min_sequence_length=min_sequence_length,\n",
    "                                        step_size=step_size)\n",
    "\n",
    "    mode = 'lstm'\n",
    "\n",
    "    run(train, test, validation, random_state, mode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
